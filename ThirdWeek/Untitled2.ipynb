{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Import relevant modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# The following lines adjust the granularity of reporting. \n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = \"{:.1f}\".format\n",
    "\n",
    "# The following line improves formatting when ouputting NumPy arrays.\n",
    "np.set_printoptions(linewidth = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train),(x_test, y_test) = tf.keras.datasets.mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  97,  96,  77, 118,  61,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,  90, 138, 235, 235, 235, 235, 235, 235, 251, 251, 248, 254, 245, 235, 190,  21,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0, 140, 251, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 189,  23,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0, 226, 254, 208, 199, 199, 199, 199, 139,  61,  61,  61,  61,  61, 128, 222, 254, 254, 189,  21,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,  38,  82,  13,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  34, 213, 254, 254, 115,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  84, 254, 254, 234,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  84, 254, 254, 234,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 106, 157, 254, 254, 243,  51,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  25, 117, 228, 228, 228, 253, 254, 254, 254, 254, 240,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  68, 119, 220, 254, 254, 254, 254, 254, 254, 254, 254, 254, 142,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  37, 187, 253, 254, 254, 254, 223, 206, 206,  75,  68, 215, 254, 254, 117,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0, 113, 219, 254, 242, 227, 115,  89,  31,   0,   0,   0,   0, 200, 254, 241,  41,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0, 169, 254, 176,  62,   0,   0,   0,   0,   0,   0,   0,  48, 231, 254, 234,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 124,   0,   0,   0,   0,   0,   0,   0,   0,   0,  84, 254, 254, 166,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 254, 238,  57,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 210, 250, 254, 168,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 242, 254, 239,  57,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  89, 251, 241,  86,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   5, 206, 246, 157,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   4, 117,  69,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output example #2917 of the training set.\n",
    "x_train[5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e900b46b70>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use false colors to visualize the array.\n",
    "plt.imshow(x_train[5000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Output row #10 of example #2917.\n",
    "x_train[2917][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output pixel #16 of row #10 of example #2900.\n",
    "x_train[2917][10][16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.         0.         0.         0.         0.         0.55294118 0.88627451 0.22352941 0.         0.         0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "#@title Double-click to see a solution to Task 1. \n",
    "\n",
    "x_train_normalized = x_train / 255.0\n",
    "x_test_normalized = x_test / 255.0\n",
    "print(x_train_normalized[2900][12]) # Output a normalized row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the plot_curve function.\n"
     ]
    }
   ],
   "source": [
    "#@title Define the plotting function\n",
    "def plot_curve(epochs, hist, list_of_metrics):\n",
    "  \"\"\"Plot a curve of one or more classification metrics vs. epoch.\"\"\"  \n",
    "  # list_of_metrics should be one of the names shown in:\n",
    "  # https://www.tensorflow.org/tutorials/structured_data/imbalanced_data#define_the_model_and_metrics  \n",
    "\n",
    "  plt.figure()\n",
    "  plt.xlabel(\"Epoch\")\n",
    "  plt.ylabel(\"Value\")\n",
    "\n",
    "  for m in list_of_metrics:\n",
    "    x = hist[m]\n",
    "    plt.plot(epochs[1:], x[1:], label=m)\n",
    "\n",
    "  plt.legend()\n",
    "\n",
    "print(\"Loaded the plot_curve function.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(my_learning_rate):\n",
    "  \"\"\"Create and compile a deep neural net.\"\"\"\n",
    "  \n",
    "  # All models in this course are sequential.\n",
    "  model = tf.keras.models.Sequential()\n",
    "\n",
    "  # The features are stored in a two-dimensional 28X28 array. \n",
    "  # Flatten that two-dimensional array into a a one-dimensional \n",
    "  # 784-element array.\n",
    "  model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
    "\n",
    "  # Define the first hidden layer.   \n",
    "  model.add(tf.keras.layers.Dense(units=32, activation='relu'))\n",
    "  \n",
    "  # Define a dropout regularization layer. \n",
    "  model.add(tf.keras.layers.Dropout(rate=0.2))\n",
    "\n",
    "  # Define the output layer. The units parameter is set to 10 because\n",
    "  # the model must choose among 10 possible output values (representing\n",
    "  # the digits from 0 to 9, inclusive).\n",
    "  #\n",
    "  # Don't change this layer.\n",
    "  model.add(tf.keras.layers.Dense(units=10, activation='softmax'))     \n",
    "                           \n",
    "  # Construct the layers into a model that TensorFlow can execute.  \n",
    "  # Notice that the loss function for multi-class classification\n",
    "  # is different than the loss function for binary classification.  \n",
    "  model.compile(optimizer=tf.keras.optimizers.Adam(lr=my_learning_rate),\n",
    "                loss=\"sparse_categorical_crossentropy\",\n",
    "                metrics=['accuracy'])\n",
    "  \n",
    "  return model    \n",
    "\n",
    "\n",
    "def train_model(model, train_features, train_label, epochs,\n",
    "                batch_size=None, validation_split=0.1):\n",
    "  \"\"\"Train the model by feeding it data.\"\"\"\n",
    "\n",
    "  history = model.fit(x=train_features, y=train_label, batch_size=batch_size,\n",
    "                      epochs=epochs, shuffle=True, \n",
    "                      validation_split=validation_split)\n",
    " \n",
    "  # To track the progression of training, gather a snapshot\n",
    "  # of the model's metrics at each epoch. \n",
    "  epochs = history.epoch\n",
    "  hist = pd.DataFrame(history.history)\n",
    "\n",
    "  return epochs, hist    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/50\n",
      "48000/48000 [==============================] - 1s 14us/sample - loss: 1.7151 - acc: 0.4498 - val_loss: 0.9743 - val_acc: 0.8036\n",
      "Epoch 2/50\n",
      "48000/48000 [==============================] - 0s 9us/sample - loss: 0.9186 - acc: 0.7305 - val_loss: 0.5653 - val_acc: 0.8574\n",
      "Epoch 3/50\n",
      "48000/48000 [==============================] - 0s 10us/sample - loss: 0.6562 - acc: 0.8019 - val_loss: 0.4379 - val_acc: 0.8816\n",
      "Epoch 4/50\n",
      "48000/48000 [==============================] - 0s 9us/sample - loss: 0.5441 - acc: 0.8367 - val_loss: 0.3725 - val_acc: 0.8992\n",
      "Epoch 5/50\n",
      "48000/48000 [==============================] - 0s 9us/sample - loss: 0.4849 - acc: 0.8560 - val_loss: 0.3391 - val_acc: 0.9068\n",
      "Epoch 6/50\n",
      "48000/48000 [==============================] - 0s 9us/sample - loss: 0.4462 - acc: 0.8693 - val_loss: 0.3142 - val_acc: 0.9128\n",
      "Epoch 7/50\n",
      "48000/48000 [==============================] - 0s 9us/sample - loss: 0.4194 - acc: 0.8767 - val_loss: 0.2966 - val_acc: 0.9179\n",
      "Epoch 8/50\n",
      "48000/48000 [==============================] - 0s 9us/sample - loss: 0.3966 - acc: 0.8835 - val_loss: 0.2814 - val_acc: 0.9227\n",
      "Epoch 9/50\n",
      "48000/48000 [==============================] - 0s 9us/sample - loss: 0.3773 - acc: 0.8895 - val_loss: 0.2689 - val_acc: 0.9244\n",
      "Epoch 10/50\n",
      "48000/48000 [==============================] - 0s 10us/sample - loss: 0.3641 - acc: 0.8930 - val_loss: 0.2591 - val_acc: 0.9278\n",
      "Epoch 11/50\n",
      "48000/48000 [==============================] - 0s 9us/sample - loss: 0.3496 - acc: 0.8976 - val_loss: 0.2498 - val_acc: 0.9293\n",
      "Epoch 12/50\n",
      "48000/48000 [==============================] - 0s 9us/sample - loss: 0.3357 - acc: 0.9032 - val_loss: 0.2424 - val_acc: 0.9312\n",
      "Epoch 13/50\n",
      "48000/48000 [==============================] - 0s 10us/sample - loss: 0.3277 - acc: 0.9040 - val_loss: 0.2344 - val_acc: 0.9342\n",
      "Epoch 14/50\n",
      "48000/48000 [==============================] - 0s 9us/sample - loss: 0.3191 - acc: 0.9067 - val_loss: 0.2294 - val_acc: 0.9366\n",
      "Epoch 15/50\n",
      "48000/48000 [==============================] - 0s 9us/sample - loss: 0.3128 - acc: 0.9094 - val_loss: 0.2238 - val_acc: 0.9376\n",
      "Epoch 16/50\n",
      "48000/48000 [==============================] - 0s 9us/sample - loss: 0.3020 - acc: 0.9126 - val_loss: 0.2194 - val_acc: 0.9373\n",
      "Epoch 17/50\n",
      "48000/48000 [==============================] - 0s 9us/sample - loss: 0.2968 - acc: 0.9133 - val_loss: 0.2144 - val_acc: 0.9396\n",
      "Epoch 18/50\n",
      "48000/48000 [==============================] - 0s 9us/sample - loss: 0.2880 - acc: 0.9158 - val_loss: 0.2082 - val_acc: 0.9414\n",
      "Epoch 19/50\n",
      "48000/48000 [==============================] - 0s 9us/sample - loss: 0.2830 - acc: 0.9168 - val_loss: 0.2041 - val_acc: 0.9426\n",
      "Epoch 20/50\n",
      "48000/48000 [==============================] - 0s 9us/sample - loss: 0.2770 - acc: 0.9186 - val_loss: 0.1995 - val_acc: 0.9433\n",
      "Epoch 21/50\n",
      "48000/48000 [==============================] - 0s 10us/sample - loss: 0.2685 - acc: 0.9214 - val_loss: 0.1962 - val_acc: 0.9449\n",
      "Epoch 22/50\n",
      "48000/48000 [==============================] - 0s 9us/sample - loss: 0.2667 - acc: 0.9222 - val_loss: 0.1958 - val_acc: 0.9443\n",
      "Epoch 23/50\n",
      "48000/48000 [==============================] - 0s 9us/sample - loss: 0.2642 - acc: 0.9231 - val_loss: 0.1908 - val_acc: 0.9461\n",
      "Epoch 24/50\n",
      "48000/48000 [==============================] - 0s 9us/sample - loss: 0.2559 - acc: 0.9247 - val_loss: 0.1868 - val_acc: 0.9475\n",
      "Epoch 25/50\n",
      "48000/48000 [==============================] - 0s 9us/sample - loss: 0.2514 - acc: 0.9256 - val_loss: 0.1842 - val_acc: 0.9486\n",
      "Epoch 26/50\n",
      "48000/48000 [==============================] - 0s 10us/sample - loss: 0.2482 - acc: 0.9279 - val_loss: 0.1820 - val_acc: 0.9482\n",
      "Epoch 27/50\n",
      "48000/48000 [==============================] - 0s 9us/sample - loss: 0.2450 - acc: 0.9279 - val_loss: 0.1787 - val_acc: 0.9488\n",
      "Epoch 28/50\n",
      "48000/48000 [==============================] - 0s 9us/sample - loss: 0.2406 - acc: 0.9278 - val_loss: 0.1762 - val_acc: 0.9510\n",
      "Epoch 29/50\n",
      "48000/48000 [==============================] - 0s 9us/sample - loss: 0.2383 - acc: 0.9307 - val_loss: 0.1732 - val_acc: 0.9514\n",
      "Epoch 30/50\n",
      "48000/48000 [==============================] - 0s 9us/sample - loss: 0.2367 - acc: 0.9289 - val_loss: 0.1713 - val_acc: 0.9507\n",
      "Epoch 31/50\n",
      "48000/48000 [==============================] - 0s 9us/sample - loss: 0.2320 - acc: 0.9319 - val_loss: 0.1699 - val_acc: 0.9529\n",
      "Epoch 32/50\n",
      "48000/48000 [==============================] - 0s 9us/sample - loss: 0.2303 - acc: 0.9315 - val_loss: 0.1675 - val_acc: 0.9526\n",
      "Epoch 33/50\n",
      "48000/48000 [==============================] - 0s 9us/sample - loss: 0.2247 - acc: 0.9328 - val_loss: 0.1673 - val_acc: 0.9527\n",
      "Epoch 34/50\n",
      "48000/48000 [==============================] - 0s 9us/sample - loss: 0.2235 - acc: 0.9344 - val_loss: 0.1660 - val_acc: 0.9532\n",
      "Epoch 35/50\n",
      "48000/48000 [==============================] - 0s 9us/sample - loss: 0.2188 - acc: 0.9350 - val_loss: 0.1650 - val_acc: 0.9530\n",
      "Epoch 36/50\n",
      "48000/48000 [==============================] - 0s 10us/sample - loss: 0.2210 - acc: 0.9344 - val_loss: 0.1634 - val_acc: 0.9533\n",
      "Epoch 37/50\n",
      "48000/48000 [==============================] - 0s 9us/sample - loss: 0.2199 - acc: 0.9351 - val_loss: 0.1609 - val_acc: 0.9544\n",
      "Epoch 38/50\n",
      "48000/48000 [==============================] - 1s 10us/sample - loss: 0.2129 - acc: 0.9361 - val_loss: 0.1595 - val_acc: 0.9553\n",
      "Epoch 39/50\n",
      "48000/48000 [==============================] - 0s 10us/sample - loss: 0.2135 - acc: 0.9355 - val_loss: 0.1575 - val_acc: 0.9554\n",
      "Epoch 40/50\n",
      "48000/48000 [==============================] - 0s 9us/sample - loss: 0.2082 - acc: 0.9381 - val_loss: 0.1564 - val_acc: 0.9548\n",
      "Epoch 41/50\n",
      "48000/48000 [==============================] - 0s 9us/sample - loss: 0.2113 - acc: 0.9367 - val_loss: 0.1559 - val_acc: 0.9559\n",
      "Epoch 42/50\n",
      "48000/48000 [==============================] - 0s 9us/sample - loss: 0.2063 - acc: 0.9375 - val_loss: 0.1547 - val_acc: 0.9563\n",
      "Epoch 43/50\n",
      "48000/48000 [==============================] - 0s 9us/sample - loss: 0.2030 - acc: 0.9386 - val_loss: 0.1551 - val_acc: 0.9563\n",
      "Epoch 44/50\n",
      "48000/48000 [==============================] - 0s 10us/sample - loss: 0.2010 - acc: 0.9386 - val_loss: 0.1530 - val_acc: 0.9572\n",
      "Epoch 45/50\n",
      "48000/48000 [==============================] - 0s 10us/sample - loss: 0.2007 - acc: 0.9395 - val_loss: 0.1528 - val_acc: 0.9573\n",
      "Epoch 46/50\n",
      "48000/48000 [==============================] - 0s 10us/sample - loss: 0.1988 - acc: 0.9411 - val_loss: 0.1523 - val_acc: 0.9571\n",
      "Epoch 47/50\n",
      "48000/48000 [==============================] - 0s 10us/sample - loss: 0.2006 - acc: 0.9400 - val_loss: 0.1508 - val_acc: 0.9580\n",
      "Epoch 48/50\n",
      "48000/48000 [==============================] - 0s 9us/sample - loss: 0.1961 - acc: 0.9401 - val_loss: 0.1495 - val_acc: 0.9578\n",
      "Epoch 49/50\n",
      "48000/48000 [==============================] - 0s 9us/sample - loss: 0.1938 - acc: 0.9417 - val_loss: 0.1498 - val_acc: 0.9575\n",
      "Epoch 50/50\n",
      "48000/48000 [==============================] - 0s 10us/sample - loss: 0.1936 - acc: 0.9426 - val_loss: 0.1491 - val_acc: 0.9573\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2656\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2657\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2658\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'accuracy'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-c2c743020313>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# Plot a graph of the metric vs. epochs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mlist_of_metrics_to_plot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mplot_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist_of_metrics_to_plot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m# Evaluate against the test set.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-72-f88e964b9d9d>\u001b[0m in \u001b[0;36mplot_curve\u001b[1;34m(epochs, hist, list_of_metrics)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist_of_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2925\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2926\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2927\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2928\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2929\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2657\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2658\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2659\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2660\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2661\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'accuracy'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The following variables are the hyperparameters.\n",
    "learning_rate = 0.003\n",
    "epochs = 50\n",
    "batch_size = 4000\n",
    "validation_split = 0.2\n",
    "\n",
    "# Establish the model's topography.\n",
    "my_model = create_model(learning_rate)\n",
    "\n",
    "# Train the model on the normalized training set.\n",
    "epochs, hist = train_model(my_model, x_train_normalized, y_train, \n",
    "                           epochs, batch_size, validation_split)\n",
    "\n",
    "# Plot a graph of the metric vs. epochs.\n",
    "list_of_metrics_to_plot = ['accuracy']\n",
    "plot_curve(epochs, hist, list_of_metrics_to_plot)\n",
    "\n",
    "# Evaluate against the test set.\n",
    "print(\"\\n Evaluate the new model against the test set:\")\n",
    "my_model.evaluate(x=x_test_normalized, y=y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
